{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_自然语言处理_Workbook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "jupytext": {
      "split_at_heading": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unpackAI/CDL101/blob/main/%E7%AC%AC%E5%9B%9B%E5%91%A8%EF%BC%9A%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/04_%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86_Workbook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j04QL-TPJy1"
      },
      "source": [
        "# 💻unpackAI的第4周工作手册 ```DL101训练营```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0joGgV0POOt"
      },
      "source": [
        "## 📕本周的学习目标\n",
        "\n",
        "* 理解建立自己的语言模型的基本过程。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJvIFM7zjGnj"
      },
      "source": [
        "## 🎸 需要的库和依赖性"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azcl-ikfOQJR",
        "outputId": "b8aa7c99-578d-4c92-bbbf-e219624484a2"
      },
      "source": [
        "!pip install -Uqq unpackai\n",
        "# !pip install -q git+https://github.com/unpackai/unpackai\n",
        "!pip install -Uqq transformers==4.10.2\n",
        "!pip install -q datasets transformers[sentencepiece]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 73 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 95 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 189 kB 8.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 22.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 312 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 48.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 50.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 45.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.4 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynOZVJ0HfD2Q"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModel,\n",
        "    pipeline,\n",
        "    set_seed,\n",
        "    Trainer,\n",
        "    TextDataset,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    AutoModelForSequenceClassification,\n",
        ")\n",
        "from unpackai.nlp import Textual, InterpEmbeddingsTokenizer\n",
        "from ipywidgets import interact\n",
        "import logging\n",
        "from fastai import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx21fMyjgV1v"
      },
      "source": [
        "## unpackAI作业部分\n",
        "\n",
        " \n",
        "* **作业1**: 浏览下面的多项选择题，并选择正确的答案。在报告会上讨论你的答案。\n",
        "* **作业2**: 建立一个完整的语言模型，从定义你的目标开始，收集数据到训练你的模型和解释结果。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2frVl71OQJi"
      },
      "source": [
        "## 任务1：多项选择题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrGS533pAUsp"
      },
      "source": [
        "1. 什么是语言模型？\n",
        "\n",
        "> A: 一个能说话的模型。\n",
        "\n",
        "> B: 一个能够通过复制和粘贴它所训练的不同部分的文本而产生文本的模型。\n",
        "\n",
        "> C: 一个能够预测一连串单词中最有可能出现的下一个单词的模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR0DZFcq_gnX"
      },
      "source": [
        "2. 什么是NLP中的标记化？\n",
        "\n",
        "> A: 代号化是将敏感数据变成非敏感数据的过程，称为 \"代号\"，可以在数据库或内部系统中使用，而不会将其带入范围。\n",
        "\n",
        "> B: 标记化是一种将单词、数字、逗号等分割成子单元的技术，以便于进一步处理。\n",
        "\n",
        "> C：标记化是一种将文本数据集分割成标记化的验证或训练数据集的技术。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY8bqKOUNrY7"
      },
      "source": [
        "3. 什么是词嵌入？\n",
        "\n",
        "> A: 词嵌入是一种词的表示方法，它允许意义相似的词有相似的表示方法。\n",
        "\n",
        "> B: 词嵌入对一个词的意义性进行评分。在一个词嵌入中，学到的特征值越高，它在文本数据集中就越有意义和重要。\n",
        "\n",
        "> C: 一个词的嵌入是一个词的学习特征。这个特征用1和-1之间的数字来描述每个词。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUbu_n7fiITe"
      },
      "source": [
        "##作业2：建立一个完整的语言模型。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1PTaXRGQKxS"
      },
      "source": [
        "### 第一步 - 定义一个ML问题并提出一个解决方案。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDEouac7xN1v"
      },
      "source": [
        "#### 1. 界定目标\n",
        "**你的目标：**\n",
        "#### 2. 描述你的数据集\n",
        "**你的数据集：**\n",
        "#### 3. 描述你的模型\n",
        "**你的模型：**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5QZmieCYbZ2"
      },
      "source": [
        "### 第二步 - 收集和构建你的数据集\n",
        "\n",
        "为了收集和设计你自己的数据集，我们为你提供了下面的 \"文本 \"搜刮工具。为此，你有两个选择:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5Uma7pnjrm5"
      },
      "source": [
        "**选项1：从一个URL收集文本。**\n",
        "\n",
        "向文本工具提供一个URL，所有的文本将被收集。我们推荐[古腾堡计划](https://gutenberg.org/)作为一个来源，这是一个超过60,000本免费电子书的集合。只需点击你喜欢的书和相应的txt文件（见以下图片）。\n",
        "\n",
        "<img src=\"https://www.dropbox.com/s/p5tyklp58d3yosa/Screen%20Shot%202021-09-13%20at%2017.49.52.png?dl=1\" alt=\"wordembeddings\" width=\"500\"/>\n",
        "\n",
        "然而，也鼓励大家尝试使用来自其他URL来源的其他数据集。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCWwVhIAjjBK"
      },
      "source": [
        "textual = Textual.from_url(\"https://gutenberg.org/files/6130/6130-0.txt\")\n",
        "textual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1iDa9dplr2h"
      },
      "source": [
        "**选项2：从路径收集文本。**\n",
        "\n",
        "如果你有一个下载的txt文件，请随时将其上传到Google Drive，并在下面的括号内输入路径。确保文件格式是txt（一种类似csv一样的文件类型）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TzPtIt0jpZc"
      },
      "source": [
        "textual = Textual.from_path(\"./the_txt_file_you_uploaded.txt\")\n",
        "textual"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYOIkqBuZAm5"
      },
      "source": [
        "###第三步 - 模型训练"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3TG7_8mZJU"
      },
      "source": [
        "我们跳过数据转换，因为标记化和数值化发生在模型训练期间。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnzDFAZZZXCf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXFzPxONZGu1"
      },
      "source": [
        "###第四步 - 解释模型并生成文本。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDmQ23JmZWrn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}